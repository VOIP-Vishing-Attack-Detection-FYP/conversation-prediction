{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Components\n",
    "1. Embedding Layer: Converts input token indices to dense vectors.\n",
    "2. Positional Encoding: Adds position information to embeddings to maintain the sequence order.\n",
    "3. Encoder and Decoder Layers: Core processing units in the transformer.\n",
    "4. Output Layer: Converts decoder output to token probabilities for generating text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph of deps:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Examining torchvision:   0%|          | 0/8 [00:00<?, ?it/s] \n",
      "Examining @/win-64::__win==0=0:  12%|█▎        | 1/8 [00:26<03:07, 26.76s/it]\n",
      "Examining @/win-64::__win==0=0:  25%|██▌       | 2/8 [00:26<01:20, 13.38s/it]\n",
      "Examining @/win-64::__cuda==12.5=0:  25%|██▌       | 2/8 [00:26<01:20, 13.38s/it]\n",
      "Examining torchaudio:  38%|███▊      | 3/8 [00:26<01:06, 13.38s/it]              \n",
      "Examining python=3.13:  50%|█████     | 4/8 [00:42<00:53, 13.38s/it]\n",
      "Examining python=3.13:  62%|██████▎   | 5/8 [00:42<00:23,  7.82s/it]\n",
      "Examining @/win-64::__archspec==1=x86_64:  62%|██████▎   | 5/8 [00:42<00:23,  7.82s/it]\n",
      "Examining cpuonly:  75%|███████▌  | 6/8 [00:42<00:15,  7.82s/it]                       \n",
      "Examining pytorch:  88%|████████▊ | 7/8 [00:42<00:07,  7.82s/it]\n",
      "                                                                \n",
      "\n",
      "Determining conflicts:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Examining conflict for torchvision pytorch torchaudio:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Examining conflict for torchvision python pytorch torchaudio:  12%|█▎        | 1/8 [00:04<00:28,  4.09s/it]\n",
      "Examining conflict for torchvision python pytorch torchaudio:  25%|██▌       | 2/8 [00:04<00:12,  2.05s/it]\n",
      "Examining conflict for torchvision cpuonly pytorch torchaudio:  25%|██▌       | 2/8 [00:07<00:12,  2.05s/it]\n",
      "Examining conflict for torchvision cpuonly pytorch torchaudio:  38%|███▊      | 3/8 [00:07<00:13,  2.76s/it]\n",
      "Examining conflict for torchvision python pytorch:  38%|███▊      | 3/8 [00:14<00:13,  2.76s/it]            \n",
      "Examining conflict for torchvision python pytorch:  50%|█████     | 4/8 [00:14<00:16,  4.14s/it]\n",
      "Examining conflict for torchvision python:  50%|█████     | 4/8 [00:16<00:16,  4.14s/it]        \n",
      "Examining conflict for torchvision python:  62%|██████▎   | 5/8 [00:16<00:10,  3.56s/it]\n",
      "Examining conflict for torchvision pytorch:  62%|██████▎   | 5/8 [00:16<00:10,  3.56s/it]\n",
      "                                                                                         \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - torchaudio -> python[version='>=2.7,<2.8.0a0|>=3.5,<3.6.0a0']\n",
      "  - torchaudio -> python[version='>=3.10,<3.11.0a0|>=3.12,<3.13.0a0|>=3.8,<3.9.0a0|>=3.9,<3.10.0a0|>=3.11,<3.12.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0']\n",
      "  - torchvision -> python[version='>=3.10,<3.11.0a0|>=3.11,<3.12.0a0|>=3.8,<3.9.0a0|>=3.9,<3.10.0a0|>=3.12,<3.13.0a0|>=3.7,<3.8.0a0|>=3.6,<3.7.0a0|>=3.5,<3.6.0a0']\n",
      "\n",
      "Your python: python=3.13\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "The following specifications were found to be incompatible with each other:\n",
      "\n",
      "Output in format: Requested package -> Available versions\n",
      "\n",
      "Package pytorch-mutex conflicts for:\n",
      "torchvision -> pytorch-mutex==1.0[build='cuda|cpu']\n",
      "torchaudio -> pytorch-mutex==1.0[build='cuda|cpu']\n",
      "cpuonly -> pytorch-mutex==1.0=cpu\n",
      "pytorch -> pytorch-mutex==1.0[build='cuda|cpu']\n",
      "\n",
      "Package setuptools conflicts for:\n",
      "torchvision -> setuptools\n",
      "pytorch -> jinja2 -> setuptools\n",
      "python=3.13 -> pip -> setuptools\n",
      "\n",
      "Package requests conflicts for:\n",
      "torchvision -> requests\n",
      "python=3.13 -> pip -> requests\n",
      "\n",
      "Package pytorch conflicts for:\n",
      "torchaudio -> pytorch[version='1.10.0|1.10.1|1.10.2|1.11.0|1.12.0|1.12.1|1.13.0|1.13.1|2.0.0|2.0.1|2.1.0|2.1.1|2.1.2|2.2.0|2.2.1|2.2.2|2.3.0|2.3.1|2.4.0|2.4.1|1.9.1|1.9.0|1.8.1|1.8.0|1.7.1|1.7.0|1.6.0']\n",
      "torchvision -> pytorch[version='1.10.0|1.10.1|1.10.2|1.11.0|1.12.0|1.12.1|1.13.0|1.13.1|2.0.0|2.0.1|2.1.0|2.1.1|2.1.2|2.2.0|2.2.1|2.2.2|2.3.0|2.3.1|2.4.0|2.4.1|1.9.1|1.9.0|1.8.1|1.8.0|1.7.1|1.7.0|1.6.0|1.5.1|2.3.*',build=*cpu*]\n",
      "\n",
      "Package typing conflicts for:\n",
      "torchvision -> typing_extensions -> typing[version='>=3.7.4']\n",
      "pytorch -> typing_extensions -> typing[version='>=3.7.4']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEmbedding\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(d_model)  # Scale by sqrt(d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    attention_weights = torch.softmax(scores, dim=-1)\n",
    "    return torch.matmul(attention_weights, value), attention_weights\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversation-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
