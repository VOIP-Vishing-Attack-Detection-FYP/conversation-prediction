{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Components\n",
    "1. Embedding Layer: Converts input token indices to dense vectors.\n",
    "2. Positional Encoding: Adds position information to embeddings to maintain the sequence order.\n",
    "3. Encoder and Decoder Layers: Core processing units in the transformer.\n",
    "4. Output Layer: Converts decoder output to token probabilities for generating text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/pb/cf_bxmzx58d421z_lfhtsfd00000gn/T/ipykernel_1390/1579222628.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7222, 0.6455, 0.3649],\n",
      "        [0.8126, 0.5875, 0.2426],\n",
      "        [0.4509, 0.0818, 0.6368],\n",
      "        [0.7041, 0.5582, 0.2735],\n",
      "        [0.2231, 0.5530, 0.5896]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(d_model)  # Scale embeddings by sqrt(d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    attention_weights = torch.softmax(scores, dim=-1)\n",
    "    return torch.matmul(attention_weights, value), attention_weights\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, d_model):\n",
    "        \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        def transform(x, linear_layer):\n",
    "            x = linear_layer(x)\n",
    "            return x.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        query, key, value = map(lambda x, func: transform(x, func), [query, key, value], [self.linear_q, self.linear_k, self.linear_v])\n",
    "\n",
    "        # Apply scaled dot product attention\n",
    "        attention_output, attention_weights = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # Concatenate attention heads\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "\n",
    "        return self.fc_out(attention_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedforward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads, d_model)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # Self-attention\n",
    "        src2 = self.attention(src, src, src, src_mask)\n",
    "        src = src + self.dropout(src2)  # Add & Norm\n",
    "        src = self.layer_norm1(src)\n",
    "        \n",
    "        # Feed-forward\n",
    "        src2 = self.feed_forward(src)\n",
    "        src = src + self.dropout(src2)  # Add & Norm\n",
    "        return self.layer_norm2(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        enc_output = self.encoder(src, src_mask)\n",
    "        output = self.fc_out(enc_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000  # Adjust according to your dataset\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "\n",
    "model = TransformerModel(vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (input_ids, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):  \u001b[38;5;66;03m# Assuming train_loader is your data loader\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         src_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Define src_mask if required by your task\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(input_ids, src_mask)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (input_ids, targets) in enumerate(train_loader):  # Assuming train_loader is your data loader\n",
    "        src_mask = None  # Define src_mask if required by your task\n",
    "        outputs = model(input_ids, src_mask)\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch} Batch {batch_idx} Loss {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages (from transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp39-cp39-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp39-cp39-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl (184 kB)\n",
      "Downloading regex-2024.9.11-cp39-cp39-macosx_10_9_x86_64.whl (287 kB)\n",
      "Downloading safetensors-0.4.5-cp39-cp39-macosx_10_12_x86_64.whl (393 kB)\n",
      "Downloading tokenizers-0.20.1-cp39-cp39-macosx_10_12_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp39-cp39-macosx_10_9_x86_64.whl (125 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 huggingface-hub-0.26.2 idna-3.10 pyyaml-6.0.2 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 tokenizers-0.20.1 tqdm-4.66.6 transformers-4.46.0 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "\n",
    "\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = [\n",
    "    (\"How are you?\", \"I’m doing well. How about you?\"),\n",
    "    (\"What’s your name?\", \"My name is John.\"),\n",
    "    # More conversations\n",
    "]\n",
    "\n",
    "\n",
    "#set the structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset #To create a custon dataset\n",
    "from transformers import GPT2Tokenizer  # You can use any tokenizer, GPT2 is just an example\n",
    "\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, conversations, tokenizer, max_length=128):\n",
    "        self.conversations = conversations\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.conversations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        conversation = self.conversations[idx]\n",
    "        input_text = conversation[0]\n",
    "        target_text = conversation[1]\n",
    "\n",
    "        # Tokenize the input and target\n",
    "        input_ids = self.tokenizer.encode(input_text, return_tensors=\"pt\", max_length=self.max_length, truncation=True, padding=\"max_length\").squeeze(0)\n",
    "        target_ids = self.tokenizer.encode(target_text, return_tensors=\"pt\", max_length=self.max_length, truncation=True, padding=\"max_length\").squeeze(0)\n",
    "\n",
    "        return input_ids, target_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ConversationDataset(conversations, tokenizer, max_length=128)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/fyp-convo-prediction/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ConversationDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (input_ids, target_ids) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx}\")\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Target IDs:\", target_ids)\n",
    "    # Forward pass through your model here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (input_ids, target_ids) in enumerate(train_loader):\n",
    "        src_mask = None  # You can define masks if needed for your model\n",
    "        outputs = model(input_ids, src_mask)\n",
    "\n",
    "        # Reshape outputs to match the target shape\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), target_ids.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch} Batch {batch_idx} Loss {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to test contributions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-convo-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
