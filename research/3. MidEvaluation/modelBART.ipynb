{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BART Conversation Completion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1) Install and Import Dependencies\n",
    "# =========================================\n",
    "# !pip install transformers datasets accelerate\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BartTokenizer,\n",
    "    BartForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CONVERSATION_ID  CONVERSATION_STEP  \\\n",
      "0                6                  1   \n",
      "1                6                  2   \n",
      "2                6                  3   \n",
      "3                6                  4   \n",
      "4                6                  5   \n",
      "\n",
      "                                                TEXT  \\\n",
      "0  Good morning, this is [Your Name]'s personal a...   \n",
      "1  Hello, my name is Jamie. I'm interested in vol...   \n",
      "2  Yes, I'm really passionate about environmental...   \n",
      "3  Great, how do I sign up, and where can I find ...   \n",
      "4  Could you send me the link, please? And my ema...   \n",
      "\n",
      "                             CONTEXT    LABEL                      FEATURES  \\\n",
      "0          Standard opening exchange  neutral                           NaN   \n",
      "1   Encourages the caller's interest  neutral      welcoming, positive_tone   \n",
      "2    Reinforces anyone can volunteer  neutral                     inclusive   \n",
      "3           Demonstrates flexibility  neutral  helpful_tone, offers_options   \n",
      "4  Fulfills caller's request quickly  neutral                 prompt_action   \n",
      "\n",
      "  ANNOTATIONS  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2) Load the Conversation CSV\n",
    "# =========================================\n",
    "# We'll assume your CSV has columns like:\n",
    "# CONVERSATION_ID, CONVERSATION_STEP, TEXT, ...\n",
    "# We will group each conversation and build partial->full pairs.\n",
    "\n",
    "df = pd.read_csv(\"/Users/ashansubodha/Desktop/VOIP Vishing/conversation-prediction/BETTER30.csv\")\n",
    "\n",
    "# Inspect columns\n",
    "print(df.head())\n",
    "\n",
    "# Example columns might be:\n",
    "# CONVERSATION_ID | CONVERSATION_STEP | TEXT | CONTEXT | LABEL (etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONVERSATION_ID</th>\n",
       "      <th>CONVERSATION_STEP</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CONTEXT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>ANNOTATIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Good morning, this is [Your Name]'s personal a...</td>\n",
       "      <td>Standard opening exchange</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello, my name is Jamie. I'm interested in vol...</td>\n",
       "      <td>Encourages the caller's interest</td>\n",
       "      <td>neutral</td>\n",
       "      <td>welcoming, positive_tone</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes, I'm really passionate about environmental...</td>\n",
       "      <td>Reinforces anyone can volunteer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>inclusive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Great, how do I sign up, and where can I find ...</td>\n",
       "      <td>Demonstrates flexibility</td>\n",
       "      <td>neutral</td>\n",
       "      <td>helpful_tone, offers_options</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Could you send me the link, please? And my ema...</td>\n",
       "      <td>Fulfills caller's request quickly</td>\n",
       "      <td>neutral</td>\n",
       "      <td>prompt_action</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>Would it be possible to receive some literatur...</td>\n",
       "      <td>\"Assistant requests official documentation fo...</td>\n",
       "      <td>scam_response</td>\n",
       "      <td>\"literature_request</td>\n",
       "      <td>decision_making_review\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>We can certainly provide information on our wo...</td>\n",
       "      <td>\"Scammer stresses the urgency of the situation.\"</td>\n",
       "      <td>scam</td>\n",
       "      <td>\"immediate_action_urgency</td>\n",
       "      <td>urgency_stress\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>I understand the urgency, but our policy is to...</td>\n",
       "      <td>\"Assistant reiterates the policy on verifying...</td>\n",
       "      <td>scam_response</td>\n",
       "      <td>\"contribution_policy_reiteration</td>\n",
       "      <td>information_for_review_request\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>I'll do my best to get you the information qui...</td>\n",
       "      <td>\"Scammer promises to send information and hig...</td>\n",
       "      <td>scam</td>\n",
       "      <td>\"information_sending_promise</td>\n",
       "      <td>support_impact_highlight\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>Thank you. We look forward to reviewing the in...</td>\n",
       "      <td>\"Assistant thanks the scammer and commits to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>\"review_commitment</td>\n",
       "      <td>decision_follow_up\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CONVERSATION_ID  CONVERSATION_STEP  \\\n",
       "0                  6                  1   \n",
       "1                  6                  2   \n",
       "2                  6                  3   \n",
       "3                  6                  4   \n",
       "4                  6                  5   \n",
       "..               ...                ...   \n",
       "645               68                  5   \n",
       "646               68                  6   \n",
       "647               68                  7   \n",
       "648               68                  8   \n",
       "649               68                  9   \n",
       "\n",
       "                                                  TEXT  \\\n",
       "0    Good morning, this is [Your Name]'s personal a...   \n",
       "1    Hello, my name is Jamie. I'm interested in vol...   \n",
       "2    Yes, I'm really passionate about environmental...   \n",
       "3    Great, how do I sign up, and where can I find ...   \n",
       "4    Could you send me the link, please? And my ema...   \n",
       "..                                                 ...   \n",
       "645  Would it be possible to receive some literatur...   \n",
       "646  We can certainly provide information on our wo...   \n",
       "647  I understand the urgency, but our policy is to...   \n",
       "648  I'll do my best to get you the information qui...   \n",
       "649  Thank you. We look forward to reviewing the in...   \n",
       "\n",
       "                                               CONTEXT           LABEL  \\\n",
       "0                            Standard opening exchange         neutral   \n",
       "1                     Encourages the caller's interest         neutral   \n",
       "2                      Reinforces anyone can volunteer         neutral   \n",
       "3                             Demonstrates flexibility         neutral   \n",
       "4                    Fulfills caller's request quickly         neutral   \n",
       "..                                                 ...             ...   \n",
       "645   \"Assistant requests official documentation fo...   scam_response   \n",
       "646   \"Scammer stresses the urgency of the situation.\"            scam   \n",
       "647   \"Assistant reiterates the policy on verifying...   scam_response   \n",
       "648   \"Scammer promises to send information and hig...            scam   \n",
       "649   \"Assistant thanks the scammer and commits to ...         neutral   \n",
       "\n",
       "                              FEATURES                       ANNOTATIONS  \n",
       "0                                  NaN                               NaN  \n",
       "1             welcoming, positive_tone                               NaN  \n",
       "2                            inclusive                               NaN  \n",
       "3         helpful_tone, offers_options                               NaN  \n",
       "4                        prompt_action                               NaN  \n",
       "..                                 ...                               ...  \n",
       "645                \"literature_request           decision_making_review\"  \n",
       "646          \"immediate_action_urgency                   urgency_stress\"  \n",
       "647   \"contribution_policy_reiteration   information_for_review_request\"  \n",
       "648       \"information_sending_promise         support_impact_highlight\"  \n",
       "649                 \"review_commitment               decision_follow_up\"  \n",
       "\n",
       "[650 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 65 conversation pairs.\n",
      "                                              source  \\\n",
      "0  Hello, this is [Your Name]'s personal assistan...   \n",
      "1  Hello, this is the personal assistant of [Your...   \n",
      "2  Hello, this is the assistant to [Your Name]. H...   \n",
      "3  Hello, this is the office of [Your Name]. How ...   \n",
      "4  Hello, you've reached the assistant for [Your ...   \n",
      "\n",
      "                                              target  \n",
      "0  Hello, this is [Your Name]'s personal assistan...  \n",
      "1  Hello, this is the personal assistant of [Your...  \n",
      "2  Hello, this is the assistant to [Your Name]. H...  \n",
      "3  Hello, this is the office of [Your Name]. How ...  \n",
      "4  Hello, you've reached the assistant for [Your ...  \n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3) Build (source, target) pairs\n",
    "# =========================================\n",
    "# We define a function that, for each conversation:\n",
    "#   - Sorts by CONVERSATION_STEP\n",
    "#   - Takes the first X% of lines as a \"partial\" conversation\n",
    "#   - Takes the entire conversation as \"full\"\n",
    "#   - Creates a row: { \"source\": partial, \"target\": full }\n",
    "\n",
    "def build_partial_full_pairs(df, partial_ratio=0.3):\n",
    "    \"\"\"\n",
    "    partial_ratio: portion of conversation to treat as the 'partial' snippet.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    grouped = df.groupby(\"CONVERSATION_ID\")\n",
    "\n",
    "    for convo_id, group in grouped:\n",
    "        group_sorted = group.sort_values(\"CONVERSATION_STEP\")\n",
    "        texts = group_sorted[\"TEXT\"].tolist()\n",
    "\n",
    "        # Full conversation as one string\n",
    "        full_convo = \"\\n\".join(texts)\n",
    "\n",
    "        # partial: first partial_ratio% lines\n",
    "        cutoff = max(1, int(len(texts) * partial_ratio))  # at least 1 line\n",
    "        partial_texts = texts[:cutoff]\n",
    "        partial_convo = \"\\n\".join(partial_texts)\n",
    "\n",
    "        rows.append({\n",
    "            \"source\": partial_convo,\n",
    "            \"target\": full_convo\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "pairs_df = build_partial_full_pairs(df, partial_ratio=0.3)\n",
    "print(f\"Built {len(pairs_df)} conversation pairs.\")\n",
    "print(pairs_df.head())\n",
    "# columns: source, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 52\n",
      "Eval examples: 13\n",
      "Sample train example:\n",
      " {'source': \"Hello, this is the assistant to [Your Name]. How may I assist you today?\\nGood day! I'm Sarah from the Global Aid Foundation. We're currently running a campaign to support victims of the recent natural disaster in [Region]. We're reaching out to compassionate individuals like [Your Name] for support.\", 'target': \"Hello, this is the assistant to [Your Name]. How may I assist you today?\\nGood day! I'm Sarah from the Global Aid Foundation. We're currently running a campaign to support victims of the recent natural disaster in [Region]. We're reaching out to compassionate individuals like [Your Name] for support.\\nAbsolutely. Our foundation has been actively involved in various relief efforts worldwide. This particular campaign focuses on providing shelter, food, and medical supplies to the affected individuals in [Region].\\nWe're in the process of updating our website with the latest campaign details. However, we can assure you that 100% of the donations go directly to the cause.\\nI understand your need for verification, but time is of the essence, and we're trying to mobilize resources quickly. A direct donation over the phone can make an immediate impact.\\nWhile we appreciate your thoroughness, we were hoping for immediate support given the urgent situation. We can provide you with a donation link right now.\\nI'll see what I can do about sending you the information. However, please consider acting quickly as every moment counts for those in need.\\nThank you for your understanding, and we hope to have your support soon. Goodbye.\"}\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 4) Create a Hugging Face Dataset\n",
    "# =========================================\n",
    "dataset = Dataset.from_pandas(pairs_df[[\"source\", \"target\"]])\n",
    "\n",
    "# Split into train/test\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset  = split_dataset[\"test\"]\n",
    "\n",
    "print(\"Train examples:\", len(train_dataset))\n",
    "print(\"Eval examples:\",  len(eval_dataset))\n",
    "print(\"Sample train example:\\n\", train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 5) Prepare the BART Tokenizer\n",
    "# =========================================\n",
    "# We'll use \"facebook/bart-base\" as an example. \n",
    "# You can also try \"facebook/bart-large\", \"facebook/bart-large-cnn\", etc.\n",
    "\n",
    "model_name = \"facebook/bart-base\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/52 [00:00<?, ? examples/s]/opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<00:00, 486.60 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 452.65 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([    0, 31414,     6,    42,    16,     5,  3167,     7,   646, 12861,\n",
      "        10704,  8174,  1336,   189,    38,  3991,    47,   452,   116, 50118,\n",
      "        12350,   183,   328,    38,   437,  4143,    31,     5,  1849, 11572,\n",
      "         2475,     4,   166,   214,   855,   878,    10,   637,     7,   323,\n",
      "         1680,     9,     5,   485,  1632,  4463,    11,   646, 43575,  8174,\n",
      "          166,   214,  3970,    66,     7, 23303,  2172,   101,   646, 12861,\n",
      "        10704,   742,    13,   323,     4,     2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor([    0, 31414,     6,    42,    16,     5,  3167,     7,   646, 12861,\n",
      "        10704,  8174,  1336,   189,    38,  3991,    47,   452,   116, 50118,\n",
      "        12350,   183,   328,    38,   437,  4143,    31,     5,  1849, 11572,\n",
      "         2475,     4,   166,   214,   855,   878,    10,   637,     7,   323,\n",
      "         1680,     9,     5,   485,  1632,  4463,    11,   646, 43575,  8174,\n",
      "          166,   214,  3970,    66,     7, 23303,  2172,   101,   646, 12861,\n",
      "        10704,   742,    13,   323,     4, 50118, 32523,     4,  1541,  4811,\n",
      "           34,    57,  7313,   963,    11,  1337,  3500,  1170,  3612,     4,\n",
      "          152,  1989,   637,  7235,    15,  1976,  5159,     6,   689,     6,\n",
      "            8,  1131,  4217,     7,     5,  2132,  2172,    11,   646, 43575,\n",
      "         8174, 50118,   170,   214,    11,     5,   609,     9, 18796,    84,\n",
      "          998,    19,     5,   665,   637,  1254,     4,   635,     6,    52,\n",
      "           64, 14144,    47,    14,   727,   207,     9,     5,  5215,   213,\n",
      "         2024,     7,     5,  1303,     4, 50118,   100,  1346,   110,   240,\n",
      "           13, 14925,     6,    53,    86,    16,     9,     5, 14981,     6,\n",
      "            8,    52,   214,   667,     7, 32336,  1915,  1335,     4,    83,\n",
      "         2228,  7096,    81,     5,  1028,    64,   146,    41,  3169,   913,\n",
      "            4, 50118,  5771,    52,  5478,   110, 10675,  1825,     6,    52,\n",
      "           58,  2818,    13,  3169,   323,   576,     5,  9047,  1068,     4,\n",
      "          166,    64,   694,    47,    19,    10,  7096,  3104,   235,   122,\n",
      "            4, 50118,   100,   581,   192,    99,    38,    64,   109,    59,\n",
      "         3981,    47,     5,   335,     4,   635,     6,  2540,  1701,  3501,\n",
      "         1335,    25,   358,  1151,  3948,    13,   167,    11,   240,     4,\n",
      "        50118, 13987,    47,    13,   110,  2969,     6,     8,    52,  1034,\n",
      "            7,    33,   110,   323,  1010,     4, 40142,     4,     2])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 6) Tokenization Function\n",
    "# =========================================\n",
    "# For seq2seq models:\n",
    "#   - \"source\" => encoder input\n",
    "#   - \"target\" => decoder output\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # examples[\"source\"] -> partial conversation text\n",
    "    # examples[\"target\"] -> full conversation text\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"source\"],\n",
    "        max_length=512,  # adjust if needed\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # Tokenize target\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"target\"],\n",
    "            max_length=512,  # adjust if needed\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "eval_dataset  = eval_dataset.map(preprocess_function,  batched=True)\n",
    "\n",
    "# Remove original columns\n",
    "train_dataset = train_dataset.remove_columns([\"source\", \"target\"])\n",
    "eval_dataset  = eval_dataset.remove_columns([\"source\", \"target\"])\n",
    "\n",
    "# Convert to PyTorch format\n",
    "train_dataset.set_format(\"torch\")\n",
    "eval_dataset.set_format(\"torch\")\n",
    "\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 7) Data Collator for Seq2Seq\n",
    "# =========================================\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model_name,\n",
    "    padding=\"longest\",\n",
    "    return_tensors=\"pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 8) Load BART For Conditional Generation\n",
    "# =========================================\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=bart-conversation-model/runs/Jan03_18-05-37_Ashans-MacBook-Pro.local,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=100,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=OptimizerNames.ADAMW_TORCH,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=bart-conversation-model,\n",
       "overwrite_output_dir=True,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=2,\n",
       "per_device_train_batch_size=2,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=bart-conversation-model,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.EPOCH,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 9) Training Arguments\n",
    "# =========================================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bart-conversation-model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "training_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 10) Define Trainer\n",
    "# =========================================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/78 [00:00<?, ?it/s]/opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729646995093/work/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "                                               \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 26/78 [00:35<00:48,  1.07it/s]/opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1283204555511475, 'eval_runtime': 3.5765, 'eval_samples_per_second': 3.635, 'eval_steps_per_second': 1.957, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 52/78 [01:00<00:22,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8945937156677246, 'eval_runtime': 0.5509, 'eval_samples_per_second': 23.599, 'eval_steps_per_second': 12.707, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [01:20<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8643345832824707, 'eval_runtime': 0.6154, 'eval_samples_per_second': 21.124, 'eval_steps_per_second': 11.375, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78/78 [01:22<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 82.7807, 'train_samples_per_second': 1.884, 'train_steps_per_second': 0.942, 'train_loss': 2.3080841455704126, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bart-conversation-finetuned/tokenizer_config.json',\n",
       " 'bart-conversation-finetuned/special_tokens_map.json',\n",
       " 'bart-conversation-finetuned/vocab.json',\n",
       " 'bart-conversation-finetuned/merges.txt',\n",
       " 'bart-conversation-finetuned/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 11) Train the Model\n",
    "# =========================================\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bart-conversation-finetuned\")\n",
    "tokenizer.save_pretrained(\"bart-conversation-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generated Conversation ===\n",
      "Caller: Hello, I'm Sanuja from State Bank of Sri Lanka. Can you please tell me your contact number?Callee: Hi, I was in a meeting now, can we talk later?\n",
      "Hello, that's my contact number. Can we talk about the meeting?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 12) Inference / Generation\n",
    "# =========================================\n",
    "# Suppose we have a partial conversation snippet, and want BART to generate\n",
    "# the rest (or entire) conversation.\n",
    "\n",
    "partial_text = \"\"\"\n",
    "Caller: Hello, I'm Sanuja from State Bank of Sri Lanka.\n",
    "Callee: Hi, I'm in a meeting now, can we talk later?\n",
    "Caller:\n",
    "\"\"\"\n",
    "# We'll feed this partial text as \"source\". The model should produce the \"target.\"\n",
    "\n",
    "# (If needed, load the saved model)\n",
    "# model = BartForConditionalGeneration.from_pretrained(\"bart-conversation-finetuned\")\n",
    "# tokenizer = BartTokenizer.from_pretrained(\"bart-conversation-finetuned\")\n",
    "import torch\n",
    "\n",
    "# Choose the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Encode your partial_text\n",
    "encoded_input = tokenizer.encode(\n",
    "    partial_text,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# Move input IDs to device\n",
    "encoded_input = encoded_input.to(device)\n",
    "\n",
    "# Generate\n",
    "model.eval()\n",
    "\n",
    "outputs = model.generate(\n",
    "    encoded_input,\n",
    "    max_length=200,\n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "encoded_input = encoded_input.cuda() if torch.cuda.is_available() else encoded_input\n",
    "\n",
    "outputs = model.generate(\n",
    "    encoded_input,\n",
    "    max_length=200,    # set a max length for generation\n",
    "    num_beams=4,       # or do_sample=True for sampling\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"=== Generated Conversation ===\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voipvishing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
