{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/voipvishing/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 1) Load and Aggregate Conversations\n",
    "########################################\n",
    "\n",
    "def load_and_aggregate(csv_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with columns:\n",
    "      - CONVERSATION_ID\n",
    "      - CONVERSATION_STEP\n",
    "      - TEXT\n",
    "      - (other columns ignored)\n",
    "\n",
    "    Returns:\n",
    "      A list of strings, where each string represents one\n",
    "      entire conversation joined by newlines.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    grouped = df.groupby(\"CONVERSATION_ID\")\n",
    "\n",
    "    conversation_texts = []\n",
    "    for convo_id, group in grouped:\n",
    "        group_sorted = group.sort_values(\"CONVERSATION_STEP\")\n",
    "        texts = group_sorted[\"TEXT\"].tolist()\n",
    "        # Join all steps with line breaks (or another delimiter)\n",
    "        full_convo = \"\\n\".join(texts)\n",
    "        conversation_texts.append(full_convo)\n",
    "\n",
    "    return conversation_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 2) Basic Tokenization & Vocab Building\n",
    "########################################\n",
    "\n",
    "def simple_tokenize(text):\n",
    "    \"\"\"\n",
    "    Splits on whitespace and basic punctuation.\n",
    "    Feel free to customize or replace with a more advanced tokenizer.\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric (keep basic punctuation if you prefer)\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,!?']\", \"\", text)\n",
    "    # Split on whitespace\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(all_texts, min_freq=1):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary from a list of text strings.\n",
    "    Args:\n",
    "      - all_texts: list of conversation strings\n",
    "      - min_freq: minimum frequency a token must have to appear in vocab\n",
    "    Returns:\n",
    "      - stoi (dict): string-to-index mapping\n",
    "      - itos (list): index-to-string list\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    \n",
    "    for txt in all_texts:\n",
    "        tokens = simple_tokenize(txt)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # Sort by frequency\n",
    "    sorted_tokens = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Filter tokens below min_freq\n",
    "    filtered_tokens = [t for t, c in sorted_tokens if c >= min_freq]\n",
    "    \n",
    "    # Special tokens\n",
    "    # For a language model, at least need PAD and UNK, ideally BOS/EOS as well\n",
    "    special_tokens = [\"<pad>\", \"<unk>\"]\n",
    "    \n",
    "    itos = special_tokens + filtered_tokens\n",
    "    stoi = {token: idx for idx, token in enumerate(itos)}\n",
    "    \n",
    "    return stoi, itos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 3) Dataset Class\n",
    "########################################\n",
    "\n",
    "class ConversationLSTMDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Splits each conversation text into tokens, then divides them into\n",
    "    fixed-length sequences for language modeling.\n",
    "\n",
    "    For example, if sequence length = 5,\n",
    "    tokens: [w1, w2, w3, w4, w5, w6, w7, w8]\n",
    "    We get samples: \n",
    "      input = [w1, w2, w3, w4, w5], target = [w2, w3, w4, w5, w6]\n",
    "      input = [w2, w3, w4, w5, w6], target = [w3, w4, w5, w6, w7]\n",
    "      ...\n",
    "    This is a sliding window approach.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conversation_texts, stoi, seq_len=10):\n",
    "        self.stoi = stoi\n",
    "        self.seq_len = seq_len\n",
    "        self.samples = []\n",
    "        \n",
    "        for text in conversation_texts:\n",
    "            tokens = simple_tokenize(text)\n",
    "            # Convert tokens -> IDs\n",
    "            token_ids = [self.stoi.get(t, self.stoi[\"<unk>\"]) for t in tokens]\n",
    "            \n",
    "            # Create (input, target) pairs in a sliding window\n",
    "            for i in range(len(token_ids) - seq_len):\n",
    "                input_seq = token_ids[i : i + seq_len]\n",
    "                target_seq = token_ids[i + 1 : i + seq_len + 1]\n",
    "                self.samples.append((input_seq, target_seq))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_seq = self.samples[idx]\n",
    "        return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# 4) Collate Function\n",
    "########################################\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch is a list of (input_seq, target_seq) tuples.\n",
    "    We'll stack them into tensors of shape (batch_size, seq_len).\n",
    "    \"\"\"\n",
    "    inputs = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    inputs = torch.stack(inputs)   # (batch_size, seq_len)\n",
    "    targets = torch.stack(targets) # (batch_size, seq_len)\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 5) Define the LSTM Model\n",
    "########################################\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        hidden: (h_0, c_0) if provided\n",
    "        \"\"\"\n",
    "        emb = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        out, hidden = self.lstm(emb, hidden)  # (batch_size, seq_len, hidden_dim)\n",
    "        logits = self.fc(out)   # (batch_size, seq_len, vocab_size)\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 6) Training Loop\n",
    "########################################\n",
    "\n",
    "def train_lstm_model(model, dataloader, optimizer, criterion, device=\"cpu\", num_epochs=5):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits, _ = model(inputs)\n",
    "            # logits shape: (batch_size, seq_len, vocab_size)\n",
    "            # targets shape: (batch_size, seq_len)\n",
    "\n",
    "            # We need to reshape for cross-entropy:\n",
    "            logits_reshaped = logits.view(-1, logits.size(-1))   # (batch_size * seq_len, vocab_size)\n",
    "            targets_reshaped = targets.view(-1)                  # (batch_size * seq_len)\n",
    "\n",
    "            loss = criterion(logits_reshaped, targets_reshaped)\n",
    "\n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# 7) Text Generation (Inference)\n",
    "########################################\n",
    "\n",
    "def generate_text(model, stoi, itos, prompt, max_tokens=20, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Given a prompt (string), tokenizes it, feeds into the model, and\n",
    "    repeatedly generates the next token in a greedy way.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    tokens = simple_tokenize(prompt)\n",
    "    input_ids = [stoi.get(t, stoi[\"<unk>\"]) for t in tokens]\n",
    "\n",
    "    # Convert to tensor of shape (1, length)\n",
    "    input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "\n",
    "    # We'll keep track of the hidden state\n",
    "    hidden = None\n",
    "\n",
    "    generated_tokens = tokens[:]  # Copy of the original prompt tokens\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_tokens):\n",
    "            # Forward pass\n",
    "            logits, hidden = model(input_tensor, hidden)\n",
    "            # Get the last time step's logits\n",
    "            last_logits = logits[:, -1, :]  # shape: (1, vocab_size)\n",
    "\n",
    "            # Greedy pick\n",
    "            next_token_id = torch.argmax(last_logits, dim=-1).item()\n",
    "            next_token_word = itos[next_token_id]\n",
    "\n",
    "            # Append to generated sequence\n",
    "            generated_tokens.append(next_token_word)\n",
    "\n",
    "            # Prepare next input\n",
    "            input_tensor = torch.tensor([[next_token_id]], dtype=torch.long).to(device)\n",
    "\n",
    "    # Join tokens into string\n",
    "    return \" \".join(generated_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1. Load & aggregate your CSV dataset\n",
    "    df = pd.read_csv(\"/Users/ashansubodha/Desktop/VOIP Vishing/conversation-prediction/FINAL_DATASET2.csv\")\n",
    "    conversation_texts = load_and_aggregate(csv_path)\n",
    "    print(\"Loaded conversations:\", len(conversation_texts))\n",
    "\n",
    "    # 2. Build vocab\n",
    "    stoi, itos = build_vocab(conversation_texts, min_freq=1)\n",
    "    print(\"Vocab size:\", len(stoi))\n",
    "\n",
    "    # 3. Create Dataset & DataLoader\n",
    "    seq_len = 10   # sliding window size\n",
    "    dataset = ConversationLSTMDataset(conversation_texts, stoi, seq_len=seq_len)\n",
    "    print(\"Number of samples (input-target pairs):\", len(dataset))\n",
    "\n",
    "    batch_size = 16\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    # 4. Instantiate the LSTM Model\n",
    "    vocab_size = len(stoi)\n",
    "    embed_dim = 100\n",
    "    hidden_dim = 128\n",
    "    num_layers = 1\n",
    "\n",
    "    model = LSTMModel(vocab_size, embed_dim, hidden_dim, num_layers=num_layers)\n",
    "\n",
    "    # 5. Define optimizer & loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 6. Train\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_lstm_model(model, dataloader, optimizer, criterion, device=device, num_epochs=5)\n",
    "\n",
    "    # 7. Text Generation Demo\n",
    "    prompt = \"Hello, this is the personal assistant of your name\"\n",
    "    generated = generate_text(model, stoi, itos, prompt, max_tokens=20, device=device)\n",
    "    print(\"\\n=== Generated Text ===\")\n",
    "    print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 1. Load & aggregate your CSV dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ashansubodha/Desktop/VOIP Vishing/conversation-prediction/FINAL_DATASET2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     conversation_texts \u001b[38;5;241m=\u001b[39m load_and_aggregate(\u001b[43mcsv_path\u001b[49m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded conversations:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(conversation_texts))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# 2. Build vocab\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_path' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voipvishing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
