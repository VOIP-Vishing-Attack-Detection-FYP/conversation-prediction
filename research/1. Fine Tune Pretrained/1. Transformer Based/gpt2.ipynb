{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I am in Sri Lanka, but what I do in that country is differentâ€”I've been here for nearly 12 years, and I've\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I am in Sri Lanka,\", max_length=30, num_return_sequences=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FINE TUNE GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (4.37.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 30.7/57.7 kB 660.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 57.7/57.7 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "   ---------------------------------------- 0.0/480.6 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 102.4/480.6 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 235.5/480.6 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 480.6/480.6 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "   ---------------------------------------- 0.0/450.5 kB ? eta -:--:--\n",
      "   ----------------- --------------------- 204.8/450.5 kB 12.2 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 204.8/450.5 kB 12.2 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 204.8/450.5 kB 12.2 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 204.8/450.5 kB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- ------------------ 225.3/450.5 kB 981.9 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 225.3/450.5 kB 981.9 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 256.0/450.5 kB 785.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 419.8/450.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 450.5/450.5 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading pyarrow-18.1.0-cp39-cp39-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/25.3 MB 11.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.8/25.3 MB 10.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.3/25.3 MB 10.1 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.7/25.3 MB 9.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.2/25.3 MB 10.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.7/25.3 MB 10.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.2/25.3 MB 10.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.6/25.3 MB 10.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.7/25.3 MB 9.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 9.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 5.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.8/25.3 MB 5.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.8/25.3 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.9/25.3 MB 4.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.9/25.3 MB 4.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.1/25.3 MB 4.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.2/25.3 MB 4.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.4/25.3 MB 4.2 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.7/25.3 MB 4.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 5.0/25.3 MB 4.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.4/25.3 MB 4.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.8/25.3 MB 4.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 4.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.2/25.3 MB 3.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.2/25.3 MB 3.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.2/25.3 MB 3.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.2/25.3 MB 3.1 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.3/25.3 MB 3.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.4/25.3 MB 3.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.6/25.3 MB 3.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 3.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.4/25.3 MB 3.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.7/25.3 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.1/25.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.4/25.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.6/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.6/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.7/25.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.8/25.3 MB 3.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 9.1/25.3 MB 3.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 9.3/25.3 MB 3.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.6/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.9/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.4/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.6/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.6/25.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.7/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 2.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 10.9/25.3 MB 2.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 2.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 2.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.1/25.3 MB 2.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.2/25.3 MB 2.6 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.5/25.3 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.6/25.3 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.8/25.3 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 12.0/25.3 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.1/25.3 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.3/25.3 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.5/25.3 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 12.7/25.3 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 12.9/25.3 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 13.1/25.3 MB 2.4 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.3/25.3 MB 2.4 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 13.5/25.3 MB 2.4 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.8/25.3 MB 2.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 14.0/25.3 MB 2.6 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 14.3/25.3 MB 2.7 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 14.6/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.2/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.5/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.8/25.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.8/25.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 15.9/25.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.0/25.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.1/25.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.2/25.3 MB 2.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.5/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 16.8/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 17.0/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.3/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.6/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 17.9/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.3/25.3 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.6/25.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.0/25.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.4/25.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.8/25.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 20.2/25.3 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.6/25.3 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.7/25.3 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.7/25.3 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.8/25.3 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.0/25.3 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.4/25.3 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.7/25.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.0/25.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.4/25.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.8/25.3 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.0/25.3 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.3/25.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 2.5 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, tqdm, requests, pyarrow, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed datasets-3.2.0 huggingface-hub-0.27.0 pyarrow-18.1.0 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0 requires torch==2.1.0, but you have torch 2.5.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\ai-backend\\lib\\site-packages (from jinja2->torch) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requirement already satisfied: accelerate in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (1.2.1)',\n",
       " 'Requirement already satisfied: transformers in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (4.37.2)',\n",
       " 'Collecting transformers',\n",
       " '  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)',\n",
       " '     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--',\n",
       " '     --------- ------------------------------ 10.2/44.1 kB ? eta -:--:--',\n",
       " '     ----------------- -------------------- 20.5/44.1 kB 165.2 kB/s eta 0:00:01',\n",
       " '     -------------------------- ----------- 30.7/44.1 kB 187.9 kB/s eta 0:00:01',\n",
       " '     -------------------------------------- 44.1/44.1 kB 216.9 kB/s eta 0:00:00',\n",
       " 'Requirement already satisfied: datasets in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (3.2.0)',\n",
       " 'Requirement already satisfied: torch in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (2.5.1)',\n",
       " 'Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from accelerate) (1.24.3)',\n",
       " 'Requirement already satisfied: packaging>=20.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from accelerate) (23.2)',\n",
       " 'Requirement already satisfied: psutil in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from accelerate) (5.9.6)',\n",
       " 'Requirement already satisfied: pyyaml in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from accelerate) (6.0.1)',\n",
       " 'Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from accelerate) (0.27.0)',\n",
       " 'Requirement already satisfied: safetensors>=0.4.3 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from accelerate) (0.4.5)',\n",
       " 'Requirement already satisfied: filelock in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from transformers) (3.12.2)',\n",
       " 'Requirement already satisfied: regex!=2019.12.17 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from transformers) (2023.6.3)',\n",
       " 'Requirement already satisfied: requests in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from transformers) (2.32.3)',\n",
       " 'Collecting tokenizers<0.22,>=0.21 (from transformers)',\n",
       " '  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)',\n",
       " 'Requirement already satisfied: tqdm>=4.27 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from transformers) (4.67.1)',\n",
       " 'Requirement already satisfied: pyarrow>=15.0.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from datasets) (18.1.0)',\n",
       " 'Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from datasets) (0.3.8)',\n",
       " 'Requirement already satisfied: pandas in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from datasets) (1.5.3)',\n",
       " 'Requirement already satisfied: xxhash in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from datasets) (3.5.0)',\n",
       " 'Requirement already satisfied: multiprocess<0.70.17 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from datasets) (0.70.16)',\n",
       " 'Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.6.0)',\n",
       " 'Requirement already satisfied: aiohttp in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from datasets) (3.9.0)',\n",
       " 'Requirement already satisfied: typing-extensions>=4.8.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from torch) (4.9.0)',\n",
       " 'Requirement already satisfied: networkx in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from torch) (3.1)',\n",
       " 'Requirement already satisfied: jinja2 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from torch) (3.1.2)',\n",
       " 'Requirement already satisfied: sympy==1.13.1 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from torch) (1.13.1)',\n",
       " 'Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from sympy==1.13.1->torch) (1.3.0)',\n",
       " 'Requirement already satisfied: attrs>=17.3.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from aiohttp->datasets) (23.1.0)',\n",
       " 'Requirement already satisfied: multidict<7.0,>=4.5 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from aiohttp->datasets) (6.0.4)',\n",
       " 'Requirement already satisfied: yarl<2.0,>=1.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from aiohttp->datasets) (1.9.2)',\n",
       " 'Requirement already satisfied: frozenlist>=1.1.1 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from aiohttp->datasets) (1.4.0)',\n",
       " 'Requirement already satisfied: aiosignal>=1.1.2 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from aiohttp->datasets) (1.3.1)',\n",
       " 'Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from aiohttp->datasets) (4.0.3)',\n",
       " 'Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from requests->transformers) (3.2.0)',\n",
       " 'Requirement already satisfied: idna<4,>=2.5 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from requests->transformers) (3.4)',\n",
       " 'Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from requests->transformers) (1.26.18)',\n",
       " 'Requirement already satisfied: certifi>=2017.4.17 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from requests->transformers) (2023.11.17)',\n",
       " 'Requirement already satisfied: colorama in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from tqdm>=4.27->transformers) (0.4.6)',\n",
       " 'Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from jinja2->torch) (2.1.1)',\n",
       " 'Requirement already satisfied: python-dateutil>=2.8.1 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from pandas->datasets) (2.8.2)',\n",
       " 'Requirement already satisfied: pytz>=2020.1 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from pandas->datasets) (2023.3)',\n",
       " 'Requirement already satisfied: six>=1.5 in c:\\\\users\\\\dell\\\\anaconda3\\\\envs\\\\ai-backend\\\\lib\\\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)',\n",
       " 'Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)',\n",
       " '   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--',\n",
       " '   ---------------------------------------- 0.0/10.1 MB 991.0 kB/s eta 0:00:11',\n",
       " '    --------------------------------------- 0.2/10.1 MB 2.4 MB/s eta 0:00:05',\n",
       " '   - -------------------------------------- 0.4/10.1 MB 2.8 MB/s eta 0:00:04',\n",
       " '   -- ------------------------------------- 0.7/10.1 MB 3.8 MB/s eta 0:00:03',\n",
       " '   ---- ----------------------------------- 1.0/10.1 MB 4.6 MB/s eta 0:00:02',\n",
       " '   ---- ----------------------------------- 1.0/10.1 MB 4.6 MB/s eta 0:00:02',\n",
       " '   ------ --------------------------------- 1.6/10.1 MB 5.2 MB/s eta 0:00:02',\n",
       " '   ------ --------------------------------- 1.7/10.1 MB 5.1 MB/s eta 0:00:02',\n",
       " '   -------- ------------------------------- 2.1/10.1 MB 5.7 MB/s eta 0:00:02',\n",
       " '   ---------- ----------------------------- 2.5/10.1 MB 5.6 MB/s eta 0:00:02',\n",
       " '   ----------- ---------------------------- 2.9/10.1 MB 5.8 MB/s eta 0:00:02',\n",
       " '   ------------ --------------------------- 3.2/10.1 MB 5.8 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 6.0 MB/s eta 0:00:02',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 2.9 MB/s eta 0:00:03',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 2.9 MB/s eta 0:00:03',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 2.9 MB/s eta 0:00:03',\n",
       " '   -------------- ------------------------- 3.6/10.1 MB 2.6 MB/s eta 0:00:03',\n",
       " '   -------------- ------------------------- 3.7/10.1 MB 2.6 MB/s eta 0:00:03',\n",
       " '   -------------- ------------------------- 3.7/10.1 MB 2.5 MB/s eta 0:00:03',\n",
       " '   --------------- ------------------------ 3.8/10.1 MB 2.5 MB/s eta 0:00:03',\n",
       " '   --------------- ------------------------ 3.9/10.1 MB 2.5 MB/s eta 0:00:03',\n",
       " '   ---------------- ----------------------- 4.2/10.1 MB 2.6 MB/s eta 0:00:03',\n",
       " '   ----------------- ---------------------- 4.3/10.1 MB 2.6 MB/s eta 0:00:03',\n",
       " '   ----------------- ---------------------- 4.5/10.1 MB 2.6 MB/s eta 0:00:03',\n",
       " '   ------------------ --------------------- 4.7/10.1 MB 2.6 MB/s eta 0:00:03',\n",
       " '   ------------------- -------------------- 4.9/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   ------------------- -------------------- 5.0/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   -------------------- ------------------- 5.2/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   -------------------- ------------------- 5.2/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   -------------------- ------------------- 5.2/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   --------------------- ------------------ 5.5/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   ---------------------- ----------------- 5.7/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   ----------------------- ---------------- 5.9/10.1 MB 2.7 MB/s eta 0:00:02',\n",
       " '   ----------------------- ---------------- 6.0/10.1 MB 2.8 MB/s eta 0:00:02',\n",
       " '   ------------------------ --------------- 6.2/10.1 MB 2.8 MB/s eta 0:00:02',\n",
       " '   ------------------------- -------------- 6.4/10.1 MB 2.8 MB/s eta 0:00:02',\n",
       " '   ------------------------- -------------- 6.5/10.1 MB 2.8 MB/s eta 0:00:02',\n",
       " '   -------------------------- ------------- 6.7/10.1 MB 2.8 MB/s eta 0:00:02',\n",
       " '   --------------------------- ------------ 6.9/10.1 MB 2.8 MB/s eta 0:00:02',\n",
       " '   --------------------------- ------------ 7.1/10.1 MB 2.9 MB/s eta 0:00:02',\n",
       " '   ---------------------------- ----------- 7.3/10.1 MB 2.9 MB/s eta 0:00:01',\n",
       " '   ----------------------------- ---------- 7.4/10.1 MB 2.9 MB/s eta 0:00:01',\n",
       " '   ------------------------------ --------- 7.6/10.1 MB 2.9 MB/s eta 0:00:01',\n",
       " '   ------------------------------ --------- 7.8/10.1 MB 2.9 MB/s eta 0:00:01',\n",
       " '   ------------------------------- -------- 8.0/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.2/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 3.0 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 2.6 MB/s eta 0:00:01',\n",
       " '   -------------------------------- ------- 8.3/10.1 MB 2.6 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.4/10.1 MB 2.5 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.4/10.1 MB 2.5 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.4/10.1 MB 2.5 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.4/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.5/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.5/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.6/10.1 MB 2.3 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 8.6/10.1 MB 2.3 MB/s eta 0:00:01',\n",
       " '   ---------------------------------- ----- 8.7/10.1 MB 2.3 MB/s eta 0:00:01',\n",
       " '   ---------------------------------- ----- 8.8/10.1 MB 2.3 MB/s eta 0:00:01',\n",
       " '   ----------------------------------- ---- 9.0/10.1 MB 2.3 MB/s eta 0:00:01',\n",
       " '   ----------------------------------- ---- 9.1/10.1 MB 2.3 MB/s eta 0:00:01',\n",
       " '   ------------------------------------ --- 9.3/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   ------------------------------------- -- 9.5/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   -------------------------------------- - 9.7/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   -------------------------------------- - 9.8/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   ---------------------------------------  10.0/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   ---------------------------------------  10.1/10.1 MB 2.4 MB/s eta 0:00:01',\n",
       " '   ---------------------------------------- 10.1/10.1 MB 2.4 MB/s eta 0:00:00',\n",
       " 'Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)',\n",
       " '   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--',\n",
       " '   -- ------------------------------------- 0.2/2.4 MB 5.3 MB/s eta 0:00:01',\n",
       " '   ----- ---------------------------------- 0.3/2.4 MB 4.2 MB/s eta 0:00:01',\n",
       " '   -------- ------------------------------- 0.5/2.4 MB 3.8 MB/s eta 0:00:01',\n",
       " '   ---------- ----------------------------- 0.6/2.4 MB 3.6 MB/s eta 0:00:01',\n",
       " '   ------------- -------------------------- 0.8/2.4 MB 3.5 MB/s eta 0:00:01',\n",
       " '   --------------- ------------------------ 0.9/2.4 MB 3.5 MB/s eta 0:00:01',\n",
       " '   ------------------ --------------------- 1.1/2.4 MB 3.5 MB/s eta 0:00:01',\n",
       " '   -------------------- ------------------- 1.2/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   ----------------------- ---------------- 1.4/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   ------------------------- -------------- 1.5/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   ---------------------------- ----------- 1.7/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   ------------------------------- -------- 1.9/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   --------------------------------- ------ 2.0/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   ------------------------------------ --- 2.2/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   -------------------------------------- - 2.3/2.4 MB 3.4 MB/s eta 0:00:01',\n",
       " '   ---------------------------------------- 2.4/2.4 MB 3.2 MB/s eta 0:00:00',\n",
       " 'Installing collected packages: tokenizers, transformers',\n",
       " '  Attempting uninstall: tokenizers',\n",
       " '    Found existing installation: tokenizers 0.15.2',\n",
       " '    Uninstalling tokenizers-0.15.2:',\n",
       " '      Successfully uninstalled tokenizers-0.15.2',\n",
       " \"  WARNING: Failed to remove contents in a temporary directory 'C:\\\\Users\\\\DELL\\\\anaconda3\\\\envs\\\\ai-backend\\\\Lib\\\\site-packages\\\\~okenizers'.\",\n",
       " '  You can safely remove it manually.',\n",
       " '  Attempting uninstall: transformers',\n",
       " '    Found existing installation: transformers 4.37.2',\n",
       " '    Uninstalling transformers-4.37.2:',\n",
       " '      Successfully uninstalled transformers-4.37.2',\n",
       " 'Successfully installed tokenizers-0.21.0 transformers-4.47.1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --upgrade accelerate transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1. Import Required Libraries\n",
    "# ========================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, \n",
    "    GPT2LMHeadModel, \n",
    "    DataCollatorForLanguageModeling, \n",
    "    AdamW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 75.41 examples/s] \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 1: Load & Prepare Data\n",
    "#\n",
    "\n",
    "# Example: load a text dataset from a file named 'train.txt'\n",
    "# Each line is treated as a separate example\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": \"train.txt\"})\n",
    "\n",
    "# Filter out empty lines if your file has blank lines\n",
    "def remove_empty_strings(example):\n",
    "    return len(example[\"text\"].strip()) > 0\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].filter(remove_empty_strings)\n",
    "\n",
    "# Initialize the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 has no real pad token\n",
    "\n",
    "# A function to tokenize each example (one line)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        max_length=128, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "# Apply the tokenizer\n",
    "tokenized_dataset = dataset[\"train\"].map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Create a DataCollator for causal language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Turn the tokenized dataset into a PyTorch Dataset \n",
    "# (datasets.Dataset already works like a PyTorch dataset, but we can make a DataLoader)\n",
    "train_dataset = tokenized_dataset\n",
    "\n",
    "# Build a DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  num_warmup_steps (`int`):\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 2: Initialize Model & Optimizer\n",
    "#\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))  # Adjust embeddings if the tokenizer size changed\n",
    "model.config.pad_token_id = model.config.eos_token_id  # Avoid warnings about missing pad_token\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Use AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:37<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 3.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:21<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Average Loss: 1.9058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:21<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Average Loss: 1.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 3: Training Loop\n",
    "#\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Iterate over batches\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        # batch is a dict from the collator: {input_ids, attention_mask, labels, etc.}\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)  # for causal LM, usually same as input_ids\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1} - Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Step 4: Save the Fine-Tuned Model\n",
    "#\n",
    "\n",
    "model.save_pretrained(\"gpt2-finetuned-custom-loop\")\n",
    "tokenizer.save_pretrained(\"gpt2-finetuned-custom-loop\")\n",
    "\n",
    "print(\"Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\anaconda3\\envs\\ai-backend\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caller: Hello, I have a question about my account.\n",
      "Callee: Yes, can you please provide your account number? Can I provide it immediately? Can I immediately transfer it to your bank account?\n",
      "â€™s Free Banking: Hello, Iâ€™â€™m calling from your bank directly. Can I provide a new banking number immediately?â€™s a number that I need to confirm immediately? Your details can be shared with our partners immediately. Can I provide a more comprehensive offer immediately?â€™s available immediately?â€™s up-to-date. Can you provide a credit card number immediately?â€™s up-to-date?â€™s available for free? Can I make an appointment now?â€™s a good idea? Can I call your bank directly?â€™s ready to discuss your new offer now?â€™s an urgent matter. Can I provide your details directly now?â€™s up to date?ï¿½\n",
      "Caller: Hello, I have a question about my account.\n",
      "Callee: Yes, can you please provide your account number? Can I provide it immediately? Can I immediately transfer it to your bank account?\n",
      "â€™s Free Banking: Hello, Iâ€™â€™m calling from your bank directly. Can I provide a new banking number immediately?â€™s a number that I need to confirm immediately? Your details can be shared with our partners immediately. Can I provide a more comprehensive offer immediately?â€™s available immediately?â€™s up-to-date. Can you provide a credit card number immediately?â€™s up-to-date?â€™s available for free? Can I make an appointment now?â€™s a good idea? Can I call your bank directly?â€™s ready to discuss your new offer now?â€™s an urgent matter. Can I provide your details directly now?â€™s up to date?ï¿½\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
    "\n",
    "model_path = \"gpt2-finetuned-custom-loop\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"Caller: Hello, I have a question about my account.\\nCallee: Yes, can you please provide your account number?\"\n",
    "outputs = generator(\n",
    "    prompt,\n",
    "    max_length=200,     # a larger max length\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,     # to allow more \"creative\" generation\n",
    "    top_k=50,\n",
    "    top_p=0.95\n",
    ")\n",
    "print(outputs[0][\"generated_text\"])\n",
    "\n",
    "# print(outputs[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callee: Could you provide more details regarding this matter? Can you send an email instead?\n",
      "Callee: That sounds important. What kind of promotion is it? Iâ€™d like to make sure I received it before I signed it. Can I send it via the official website?\n",
      "Callee: Sure, let me check your account immediately. What kind of promotion is it? What kind of promotion is it? What kind of promotion should I send it via?\n",
      "Callee: Iâ€™d like to make sure I received it before I signed it. Can I send it via the official website?â€™s an automated messaging system that automatically sends you an automated email? Can I send it via the official website instead?â€™s not an automated message? Could you authorize it? Can I send it via the official website instead?â€™s not an automated message? Can\n"
     ]
    }
   ],
   "source": [
    "conversation_history = \"\"\"Caller: Hello, I have a question about my account.\\nCallee:\"\"\"\n",
    "while True:\n",
    "    # Generate the Callee's response\n",
    "    outputs = generator(\n",
    "        conversation_history,\n",
    "        max_length=200,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # handle GPT-2's lack of pad token\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generated_text = outputs[0][\"generated_text\"]\n",
    "\n",
    "    # Extract only the newly generated part after 'Callee:'\n",
    "    new_text = generated_text[len(conversation_history):]\n",
    "\n",
    "    # Print or store the Callee's response\n",
    "    print(\"Callee:\", new_text.strip())\n",
    "\n",
    "    # Then get user input (Caller) to continue the conversation\n",
    "    user_input = input(\"Caller: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    # Append the new user line to conversation\n",
    "    conversation_history += f\"Callee:{new_text}\\nCaller: {user_input}\\nCallee:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
